{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fae90a30",
   "metadata": {},
   "source": [
    "## Model training\n",
    "in this part we will train a machine learning model on the cleaned BBC data set. This implies that we will first train four models and then test our models on a cleaned test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e7750420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eb6338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the train set\n",
    "train = './BBC_data/cleaned_Train.csv'\n",
    "train_data = pd.read_csv(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212c8403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>len_of_article</th>\n",
       "      <th>truncated</th>\n",
       "      <th>len_of_truncated_article</th>\n",
       "      <th>clean_truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>1866</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>200</td>\n",
       "      <td>worldcom exboss launches defence lawyers defen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>2016</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>200</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>3104</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>200</td>\n",
       "      <td>bbc poll indicates economic gloom citizens maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "      <td>3618</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>200</td>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "      <td>2190</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>200</td>\n",
       "      <td>enron bosses 168m payout eighteen former enron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ArticleId                                               Text  \\\n",
       "0           0       1833  worldcom ex-boss launches defence lawyers defe...   \n",
       "1           1        154  german business confidence slides german busin...   \n",
       "2           2       1101  bbc poll indicates economic gloom citizens in ...   \n",
       "3           3       1976  lifestyle  governs mobile choice  faster  bett...   \n",
       "4           4        917  enron bosses in $168m payout eighteen former e...   \n",
       "\n",
       "   Category  len_of_article  \\\n",
       "0  business            1866   \n",
       "1  business            2016   \n",
       "2  business            3104   \n",
       "3      tech            3618   \n",
       "4  business            2190   \n",
       "\n",
       "                                           truncated  \\\n",
       "0  worldcom ex-boss launches defence lawyers defe...   \n",
       "1  german business confidence slides german busin...   \n",
       "2  bbc poll indicates economic gloom citizens in ...   \n",
       "3  lifestyle  governs mobile choice  faster  bett...   \n",
       "4  enron bosses in $168m payout eighteen former e...   \n",
       "\n",
       "   len_of_truncated_article                                    clean_truncated  \n",
       "0                       200  worldcom exboss launches defence lawyers defen...  \n",
       "1                       200  german business confidence slides german busin...  \n",
       "2                       200  bbc poll indicates economic gloom citizens maj...  \n",
       "3                       200  lifestyle governs mobile choice faster better ...  \n",
       "4                       200  enron bosses 168m payout eighteen former enron...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f34ff",
   "metadata": {},
   "source": [
    "### Label encoding \n",
    "As a preliminary step, we have to perform label encoding. This will transform our textual labels into numbers between 0 and number of classes - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4710eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "train_data['category_target'] = label_encoder.fit_transform(train_data['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47e6403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>len_of_article</th>\n",
       "      <th>truncated</th>\n",
       "      <th>len_of_truncated_article</th>\n",
       "      <th>clean_truncated</th>\n",
       "      <th>category_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>1866</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>200</td>\n",
       "      <td>worldcom exboss launches defence lawyers defen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>2016</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>200</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ArticleId                                               Text  \\\n",
       "0           0       1833  worldcom ex-boss launches defence lawyers defe...   \n",
       "1           1        154  german business confidence slides german busin...   \n",
       "\n",
       "   Category  len_of_article  \\\n",
       "0  business            1866   \n",
       "1  business            2016   \n",
       "\n",
       "                                           truncated  \\\n",
       "0  worldcom ex-boss launches defence lawyers defe...   \n",
       "1  german business confidence slides german busin...   \n",
       "\n",
       "   len_of_truncated_article  \\\n",
       "0                       200   \n",
       "1                       200   \n",
       "\n",
       "                                     clean_truncated  category_target  \n",
       "0  worldcom exboss launches defence lawyers defen...                0  \n",
       "1  german business confidence slides german busin...                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001d602",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test sets \n",
    "In order to have a test set on which we can test our model, we need to sacrifice part of our data and assign it to a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3c8ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we form the features and targets for both train and test set. \n",
    "#We are assigning 80% of the data to the train set, and 20% to the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data['clean_truncated'], \n",
    "                                                    train_data['category_target'], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddc02e",
   "metadata": {},
   "source": [
    "Now we need to perform text vectorization. That is, transform the text into a ector of numbers. We need to do this because we will then have to train our model on numerical features rather than text. \n",
    "\n",
    "Concretely we apply the method TfidfVectorizer which transforms each quote into a vector of numbers which represent for each word, the frequency of appearance in the sentence and in the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1bb592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to convert the text in vectorial form \n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "234e93c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1192, 200)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed311d09",
   "metadata": {},
   "source": [
    "### Building the Models\n",
    "Here we will train four models only with the train dataset. We will then directly assess the model by computing the accuracy on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf56e93",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "The first model we will train is random forest. For theoretical background, see notebook of milestone 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1b841d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8120805369127517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        76\n",
      "           1       0.92      0.77      0.84        47\n",
      "           2       0.86      0.80      0.83        55\n",
      "           3       0.81      0.88      0.84        65\n",
      "           4       0.67      0.78      0.72        55\n",
      "\n",
      "    accuracy                           0.81       298\n",
      "   macro avg       0.82      0.81      0.81       298\n",
      "weighted avg       0.82      0.81      0.81       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#declare and fit the model\n",
    "model  = RandomForestClassifier(random_state=1)\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "#make predictions on the testset\n",
    "model_predictions = model.predict(features_test)\n",
    "\n",
    "#print accuracy and other indicative values\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a80f7662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the default parameters of random forest\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24416b7",
   "metadata": {},
   "source": [
    "As we see, random forest gives an accuracy of 0.81. Now we can try to increase the accuracy by tuning some of the hyperparameters.\n",
    "\n",
    "We will tune four hyperparameters: the number of trees to build in each model, the maximal depth, the minimum number of samples needed for a split, and the minimum number of samples in a leaf. To do this we will define several possible values for each of these parameters and then build one model for each possible combination of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b6941972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "#Define a four hyperparameters to tune\n",
    "n_estimators = [50, 100, 150, 200]\n",
    "max_depth = [25, 30, 35]\n",
    "min_samples_split = [3, 4, 5, 6, 7]\n",
    "min_samples_leaf = [1, 2, 3, 4] \n",
    "\n",
    "#define a dict with the different hyperparameters\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "#perform grid search with 3-fold cross validation\n",
    "gridF = GridSearchCV(model, hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "921cb5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 35,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 4,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the best values according to the 3-fold cross validation\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd589d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8154362416107382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84        76\n",
      "           1       0.97      0.79      0.87        47\n",
      "           2       0.88      0.78      0.83        55\n",
      "           3       0.72      0.92      0.81        65\n",
      "           4       0.74      0.73      0.73        55\n",
      "\n",
      "    accuracy                           0.82       298\n",
      "   macro avg       0.83      0.81      0.82       298\n",
      "weighted avg       0.83      0.82      0.82       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train the model again but with tuned hyperparameters. \n",
    "model1  = RandomForestClassifier(random_state=1,max_depth= 35, min_samples_leaf= 1, min_samples_split= 4, n_estimators= 200)\n",
    "model1.fit(features_train, labels_train)\n",
    "\n",
    "#Test the model on the test set\n",
    "model_predictions = model1.predict(features_test)\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3f436b",
   "metadata": {},
   "source": [
    "We see that the accuracy is slightly better than before. It is now of 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68877801",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "Now we will train a model with logistic regression. Again we will assess the accuracy by applying the model to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5b2bbc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8087248322147651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83        76\n",
      "           1       0.86      0.81      0.84        47\n",
      "           2       0.84      0.78      0.81        55\n",
      "           3       0.85      0.82      0.83        65\n",
      "           4       0.71      0.75      0.73        55\n",
      "\n",
      "    accuracy                           0.81       298\n",
      "   macro avg       0.81      0.80      0.81       298\n",
      "weighted avg       0.81      0.81      0.81       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model using the train sataset\n",
    "model = LogisticRegression()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "#test the model\n",
    "model_predictions = model.predict(features_test)\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee513b",
   "metadata": {},
   "source": [
    "We see that the accuracy of this model is 0.81. We can again tune one hyperparameter, the inverse of the regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6ce8c351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we define the values to try for the hypermarameter\n",
    "param_grid = {'C': [0.1,0.001,1]}\n",
    "\n",
    "#perform grid search with 3-fold cross validation\n",
    "clf = GridSearchCV(model, param_grid, cv = 3, verbose = 1)\n",
    "\n",
    "bestF = clf.fit(features_train, labels_train)\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1c015c",
   "metadata": {},
   "source": [
    "Here we see that the optimal C is 1, which is the default value. Therefore our model does not change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c795e06",
   "metadata": {},
   "source": [
    "#### KNN\n",
    "Here we will try a KNN model. Again we will test the model on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "44d91cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.674496644295302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        76\n",
      "           1       0.68      0.72      0.70        47\n",
      "           2       0.80      0.65      0.72        55\n",
      "           3       0.56      0.74      0.64        65\n",
      "           4       0.66      0.53      0.59        55\n",
      "\n",
      "    accuracy                           0.67       298\n",
      "   macro avg       0.69      0.67      0.67       298\n",
      "weighted avg       0.69      0.67      0.67       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model using the train sataset\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "#test the model\n",
    "model_predictions = model.predict(features_test)\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "edd3ba1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the parameters of the default KNN model\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bb9bc5",
   "metadata": {},
   "source": [
    "The accuracy of the KNN model is of 0.67. For this model we can again tune two parameters, the number of nearest neighbors and the Power parameter for the Minkowski metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "50b96628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n"
     ]
    }
   ],
   "source": [
    "#Here we define the values to try for the hyperparameters\n",
    "params_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7], \n",
    "              'p': [1, 2, 3, 4, 5]}\n",
    "\n",
    "#perform grid search with 3-fold cross validation\n",
    "gridF = GridSearchCV(model, params_KNN, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5a2f9dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1, 'p': 5}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the resulting values for the hyperparameters\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6a3e1bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5201342281879194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.46        76\n",
      "           1       0.56      0.60      0.58        47\n",
      "           2       0.82      0.51      0.63        55\n",
      "           3       0.42      0.71      0.53        65\n",
      "           4       0.49      0.38      0.43        55\n",
      "\n",
      "    accuracy                           0.52       298\n",
      "   macro avg       0.56      0.52      0.53       298\n",
      "weighted avg       0.55      0.52      0.52       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Perform again fitting and testing of the model with tuned hyperparameters\n",
    "model = KNeighborsClassifier(n_neighbors=5,p=1)\n",
    "model.fit(features_train, labels_train)\n",
    "model_predictions = model.predict(features_test)\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8590",
   "metadata": {},
   "source": [
    "With the tuned hyperparameters we get an accuracy of 0.52, which is worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a185ca",
   "metadata": {},
   "source": [
    "#### Naive Bayes classifier\n",
    "Here we build and test a naive bayes classifier model. We will not tune any parameters for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5ec4387d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7281879194630873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.62      0.71        76\n",
      "           1       0.93      0.53      0.68        47\n",
      "           2       0.87      0.75      0.80        55\n",
      "           3       0.75      0.91      0.82        65\n",
      "           4       0.51      0.82      0.63        55\n",
      "\n",
      "    accuracy                           0.73       298\n",
      "   macro avg       0.78      0.72      0.73       298\n",
      "weighted avg       0.78      0.73      0.73       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model\n",
    "model = GaussianNB()\n",
    "model.fit(features_train, labels_train)\n",
    "\n",
    "#test the model\n",
    "model_predictions = model.predict(features_test)\n",
    "print('Accuracy: ', accuracy_score(labels_test, model_predictions))\n",
    "print(classification_report(labels_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32788f51",
   "metadata": {},
   "source": [
    "### Doc2Vec\n",
    "Since our performances are not particularly high, we will try a different representation of our news articles. Fow this we will use Doc2Vec. Basically it is a different way to give numerical values to the truncated articles. Each article will be represented as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f02a1ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom exboss launches defence lawyers defen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens maj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle governs mobile choice faster better ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses 168m payout eighteen former enron...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Category\n",
       "0  worldcom exboss launches defence lawyers defen...         0\n",
       "1  german business confidence slides german busin...         0\n",
       "2  bbc poll indicates economic gloom citizens maj...         0\n",
       "3  lifestyle governs mobile choice faster better ...         4\n",
       "4  enron bosses 168m payout eighteen former enron...         0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We define a new dataset with just the truncated news articles and the corresponding category.\n",
    "bbc = pd.DataFrame()\n",
    "bbc['Text'] = train_data['clean_truncated']\n",
    "bbc['Category'] = train_data['category_target']\n",
    "bbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "40d2f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a method to assign each document with a tag. This is important for the subsequent steps where we will use Gensim's \n",
    "#Doc2Vec implementation. \n",
    "def label_sentences(corpus, label_type):\n",
    "    labeled = []\n",
    "\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    \n",
    "    return labeled\n",
    "\n",
    "\n",
    "#Here we split again in test and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(bbc.Text, bbc.Category, random_state=0, test_size=0.3)\n",
    "\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2037ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1490/1490 [00:00<00:00, 879841.33it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1497247.95it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494383.78it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494383.78it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1495814.49it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1489042.88it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494741.20it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 747728.28it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 746477.90it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1493669.45it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1495098.79it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1495456.56it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1496172.60it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494383.78it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494741.20it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494383.78it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494383.78it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1493312.54it/s]\n",
      "100%|██████████| 1490/1490 [00:00<?, ?it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1492955.80it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1494383.78it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 747370.60it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 746388.74it/s]\n",
      "100%|██████████| 1490/1490 [00:00<00:00, 1504818.92it/s]\n"
     ]
    }
   ],
   "source": [
    "#Here we train the Doc2Vec model using 30 epochs\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5a10b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this method, we convert the articles into vectors\n",
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.dv[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207197bd",
   "metadata": {},
   "source": [
    "Now we will tran again the same models: Random forest, logistic regression, KNN and Naive Bayes. \n",
    "\n",
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "5af1f768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.901565995525727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89       103\n",
      "           1       0.90      0.92      0.91        89\n",
      "           2       0.88      0.91      0.90        81\n",
      "           3       0.90      0.97      0.93        97\n",
      "           4       0.90      0.83      0.86        77\n",
      "\n",
      "    accuracy                           0.90       447\n",
      "   macro avg       0.90      0.90      0.90       447\n",
      "weighted avg       0.90      0.90      0.90       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model\n",
    "model = RandomForestClassifier()\n",
    "model = model.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "#Test the model\n",
    "model_prediction = model.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(model_prediction, y_test))\n",
    "print(classification_report(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2b248",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.9 with the default parameters of random forest. We will again try to tune the hyperparameters, exactly like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "32030795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    }
   ],
   "source": [
    "#Here we define the values to try for the hyperparameters\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "#perform grid search with 3-fold cross validation\n",
    "gridF = GridSearchCV(model, hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "530e405d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the chosen parameters by the cross validation\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "086837ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9082774049217002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       103\n",
      "           1       0.93      0.91      0.92        89\n",
      "           2       0.85      0.94      0.89        81\n",
      "           3       0.91      0.98      0.95        97\n",
      "           4       0.93      0.83      0.88        77\n",
      "\n",
      "    accuracy                           0.91       447\n",
      "   macro avg       0.91      0.91      0.91       447\n",
      "weighted avg       0.91      0.91      0.91       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Again we fit and test the model but with the chosen values for the hyperparameters\n",
    "model = RandomForestClassifier(max_depth=30,min_samples_leaf=1,min_samples_split=2,n_estimators=1200)\n",
    "model = model.fit(train_vectors_dbow, y_train)\n",
    "model_prediction = model.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(model_prediction, y_test))\n",
    "print(classification_report(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9614b",
   "metadata": {},
   "source": [
    "The accuracy slightly improves to 0.91."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c342644",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "333c3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9194630872483222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92       103\n",
      "           1       0.93      0.92      0.93        89\n",
      "           2       0.86      0.94      0.90        81\n",
      "           3       0.93      0.97      0.95        97\n",
      "           4       0.93      0.86      0.89        77\n",
      "\n",
      "    accuracy                           0.92       447\n",
      "   macro avg       0.92      0.92      0.92       447\n",
      "weighted avg       0.92      0.92      0.92       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "model = model.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "#Test the model\n",
    "model_prediction = model.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(model_prediction, y_test))\n",
    "print(classification_report(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678fc54f",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.92. Again we can try to tune the hyperparameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "fbaa30e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we define the values to try for the hyperparameters\n",
    "param_grid = {'C': [0.0001,0.001, 0.01, 0.1, 1, 10]}\n",
    "\n",
    "#perform grid search with 3-fold cross validation\n",
    "clf = GridSearchCV(model, param_grid, cv = 3, verbose = 1)\n",
    "\n",
    "bestF = clf.fit(features_train, labels_train)\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94c519",
   "metadata": {},
   "source": [
    "The optimal value for C is 1, which is already the default value. Therefore our model and accuracy do not change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38629b",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "6d761d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9194630872483222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       103\n",
      "           1       0.89      0.92      0.91        89\n",
      "           2       0.88      0.93      0.90        81\n",
      "           3       0.99      0.98      0.98        97\n",
      "           4       0.89      0.84      0.87        77\n",
      "\n",
      "    accuracy                           0.92       447\n",
      "   macro avg       0.92      0.92      0.92       447\n",
      "weighted avg       0.92      0.92      0.92       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model\n",
    "model = KNeighborsClassifier()\n",
    "model = model.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "#Test the model\n",
    "model_prediction = model.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(model_prediction, y_test))\n",
    "print(classification_report(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4588bf19",
   "metadata": {},
   "source": [
    "We get an accuracy of 0.92. Again we can perform some hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "23e3b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 21 candidates, totalling 63 fits\n"
     ]
    }
   ],
   "source": [
    "#Here we define the values to try for the hyperparameters\n",
    "params_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7], \n",
    "              'p': [1, 2, 3]}\n",
    "\n",
    "#perform grid search with 3-fold cross validation\n",
    "gridF = GridSearchCV(model, params_KNN, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "dfb823a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 7, 'p': 2}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the chosen parameters by the cross validation\n",
    "bestF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "491aaf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9172259507829977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.90       103\n",
      "           1       0.92      0.92      0.92        89\n",
      "           2       0.88      0.94      0.91        81\n",
      "           3       0.96      0.99      0.97        97\n",
      "           4       0.89      0.86      0.87        77\n",
      "\n",
      "    accuracy                           0.92       447\n",
      "   macro avg       0.92      0.92      0.92       447\n",
      "weighted avg       0.92      0.92      0.92       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Again we fit and test the model but with the chosen values for the hyperparameters\n",
    "model = KNeighborsClassifier(n_neighbors=7,p=2)\n",
    "model = model.fit(train_vectors_dbow, y_train)\n",
    "model_prediction = model.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(model_prediction, y_test))\n",
    "print(classification_report(y_test, model_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde04489",
   "metadata": {},
   "source": [
    "We end up with an accuracy of 0.92 but slightly lower than with the default parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de4947b",
   "metadata": {},
   "source": [
    "#### Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bf1a2613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8926174496644296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       103\n",
      "           1       0.88      0.94      0.91        89\n",
      "           2       0.85      0.90      0.87        81\n",
      "           3       0.95      0.96      0.95        97\n",
      "           4       0.84      0.82      0.83        77\n",
      "\n",
      "    accuracy                           0.89       447\n",
      "   macro avg       0.89      0.89      0.89       447\n",
      "weighted avg       0.89      0.89      0.89       447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define and fit the model\n",
    "model = GaussianNB()\n",
    "model.fit(train_vectors_dbow, y_train)\n",
    "\n",
    "#Test the model\n",
    "model_predictions = model.predict(test_vectors_dbow)\n",
    "print('Accuracy: ', accuracy_score(y_test, model_predictions))\n",
    "print(classification_report(y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8e8c97",
   "metadata": {},
   "source": [
    "We obtain an accuracy of 0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c4cdc3",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "We trained and tested several models for both ways of representing sentences as numerical values. \n",
    "From the accuracies that we have found, it seems that the best models are KNN and logistic regression, which both have the same accuracy of 0.92."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
